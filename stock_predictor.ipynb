{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 0.035481985276189544\n",
      "Iteration 100: Cost = 0.007523320556476878\n",
      "Iteration 200: Cost = 0.0037774277478670026\n",
      "Iteration 300: Cost = 0.003275554247316674\n",
      "Iteration 400: Cost = 0.0032083133988931125\n",
      "Iteration 500: Cost = 0.0031993044918841515\n",
      "Iteration 600: Cost = 0.003198097481452265\n",
      "Iteration 700: Cost = 0.00319793576658705\n",
      "Iteration 800: Cost = 0.003197914100081989\n",
      "Iteration 900: Cost = 0.003197911197210686\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 16s 125ms/step - loss: 0.0079\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.0011\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 9.6072e-04\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 7s 126ms/step - loss: 0.0010\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.0011\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.0011\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 9.2269e-04\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 8.4763e-04\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 8s 153ms/step - loss: 8.5128e-04\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 9.6731e-04\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 8.2736e-04\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 8.4588e-04\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 7.8918e-04\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 6.7314e-04\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 8s 161ms/step - loss: 6.5287e-04\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 7s 124ms/step - loss: 6.5159e-04\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 6.5946e-04\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 6.6142e-04\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 6.5469e-04\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 6.1097e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\STUDY\\Final Project\\Stock Market Predictor\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n",
      "21/21 [==============================] - 3s 48ms/step\n",
      "LSTM RMSE: 6.134489141148141\n",
      "Linear Regression RMSE: 76.13598226504504\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Fetch stock data\n",
    "stock = \"GOOG\"\n",
    "end_date = pd.Timestamp.now()\n",
    "start_date = end_date - pd.DateOffset(years=10)\n",
    "data = yf.download(stock, start=start_date, end=end_date)\n",
    "\n",
    "# Prepare data for training and testing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[[\"Close\"]])\n",
    "window_size = 100\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(len(scaled_data) * 0.7)\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Prepare LSTM training data\n",
    "x_train, y_train = [], []\n",
    "for i in range(window_size, len(train_data)):\n",
    "    x_train.append(train_data[i - window_size:i])\n",
    "    y_train.append(train_data[i])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Prepare Linear Regression training data\n",
    "x_train_lr = np.arange(0, len(train_data)).reshape(-1, 1)  # Time as feature\n",
    "y_train_lr = train_data.reshape(-1, 1)\n",
    "\n",
    "# Normalize features for Linear Regression\n",
    "def normalize_features(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "x_train_lr = normalize_features(x_train_lr)\n",
    "\n",
    "# Initialize model parameters\n",
    "def initialize_params(n):\n",
    "    return np.zeros((n, 1)), 0  # weights and bias (theta)\n",
    "\n",
    "# Compute the cost function\n",
    "def compute_cost(X, y, w, b):\n",
    "    m = len(X)\n",
    "    predictions = X.dot(w) + b\n",
    "    cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2)\n",
    "    return cost\n",
    "\n",
    "# Perform Gradient Descent\n",
    "def gradient_descent(X, y, w, b, learning_rate, iterations):\n",
    "    m = len(X)\n",
    "    cost_history = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        predictions = X.dot(w) + b\n",
    "        dw = (1 / m) * X.T.dot(predictions - y)\n",
    "        db = (1 / m) * np.sum(predictions - y)\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        cost = compute_cost(X, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Cost = {cost}\")\n",
    "    \n",
    "    return w, b, cost_history\n",
    "\n",
    "# Train the Linear Regression model using Gradient Descent\n",
    "w, b, cost_history = gradient_descent(x_train_lr, y_train_lr, np.zeros((x_train_lr.shape[1], 1)), 0, 0.01, 1000)\n",
    "\n",
    "# Save the regression model parameters (weights and bias)\n",
    "np.save(\"saved_models/linear_regression_weights.npy\", w)\n",
    "np.save(\"saved_models/linear_regression_bias.npy\", b)\n",
    "\n",
    "# Save the scaler for future use\n",
    "if not os.path.exists(\"saved_models\"):\n",
    "    os.makedirs(\"saved_models\")\n",
    "np.save(\"saved_models/scaler_minmax.npy\", scaler.min_)\n",
    "np.save(\"saved_models/scaler_scale.npy\", scaler.scale_)\n",
    "\n",
    "# Build and train the LSTM model (same as before)\n",
    "\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(units=1))\n",
    "\n",
    "lstm_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "lstm_model.fit(x_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Save the LSTM model\n",
    "lstm_model.save(\"saved_models/pretrained_stock_model.h5\")\n",
    "print(\"Models saved successfully.\")\n",
    "\n",
    "# Evaluate both models on test data\n",
    "# LSTM evaluation\n",
    "x_test, y_test = [], []\n",
    "for i in range(window_size, len(test_data)):\n",
    "    x_test.append(test_data[i - window_size:i])\n",
    "    y_test.append(test_data[i])\n",
    "\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "lstm_predictions = lstm_model.predict(x_test)\n",
    "inv_lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "inv_y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Linear Regression evaluation\n",
    "x_test_lr = np.arange(train_size, len(scaled_data)).reshape(-1, 1)\n",
    "x_test_lr = normalize_features(x_test_lr)  # Normalize the test features for Linear Regression\n",
    "lr_predictions = x_test_lr.dot(w) + b\n",
    "inv_lr_predictions = scaler.inverse_transform(lr_predictions)\n",
    "\n",
    "# Calculate errors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lstm_rmse = np.sqrt(mean_squared_error(inv_y_test, inv_lstm_predictions))\n",
    "lr_rmse = np.sqrt(mean_squared_error(data[\"Close\"][train_size:].values, inv_lr_predictions))\n",
    "\n",
    "print(f\"LSTM RMSE: {lstm_rmse}\")\n",
    "print(f\"Linear Regression RMSE: {lr_rmse}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
